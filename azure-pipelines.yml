# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
- master

pool:
  name: Default
steps:
- bash: |
    export PYTHONUNBUFFERED=1
    echo $USER
    set +x
    stf --docker-image-dont-pull test --sch-server-url '$(DEV_SCH_URL)' --sch-username '$(DEV_SCH_USER)' --sch-password "$(DEV_SCH_PASSWORD)"  --pipeline_id "$(DEV_PIPELINE_ID)" --elasticsearch-url '$(DEV_ELASTICSEARCH_URL)' --cluster-server '$(DEV_KAFKA_URL)' --kafka-version 2.7.0 --kafka-zookeeper $(DEV_ZK_URL) -vv --upgrade-jobs --junit-xml=/root/tests/output/test-output.xml
    sudo chown -R azureuser:azureuser /home/azureuser/myagent
  displayName: 'Run Tests on Streamsets Pipeline'
- task: PublishTestResults@2
  condition: succeeded()
  inputs:
    testResultsFiles: '**/test-*.xml'
    testRunTitle: 'Publish test results for Kafka To ElasticSearch Streamsets Pipeline'
    failTaskOnFailedTests: true
- task: Bash@3
  condition: succeeded()
  inputs:
    targetType: 'inline'
    noRc: false
    script: echo $MYSECRET,$(QA_SCH_URL)
  env:
    MYSECRET: $Foo
- task: PythonScript@0
  inputs:
    scriptSource: filePath
    scriptPath: export_pipeline_from_dev.py
    pythonInterpreter: /usr/bin/python3
    arguments: --pipeline_id $(DEV_PIPELINE_ID) --dev_sch_url $(DEV_SCH_URL) --dev_sch_user $(DEV_SCH_USER) --dev_sch_password $(DEV_SCH_PASSWORD) --qa_pipeline_name $(QA_PIPELINE_NAME) --qa_sch_url $(QA_SCH_URL) --qa_sch_user $(QA_SCH_USER) --qa_sch_password $(QA_SCH_PASSWORD)